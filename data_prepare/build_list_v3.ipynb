{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build train/test list\n",
    "1. set a ratio for training data (you can change this)\n",
    "2. go to rgb-images folder, save folder names (clip_ref) for training and testing in a list\n",
    "3. save to txt\n",
    "\n",
    "### How to run this\n",
    "1. after running video_preprocessing (you have all frames in folders, labels in folders)\n",
    "2. create a folder called splitfiles under data\n",
    "3. run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDS(array):\n",
    "    if '.DS_Store' in array:\n",
    "        array.remove('.DS_Store')\n",
    "    \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Nclasses(path, N):\n",
    "    '''\n",
    "    This function is used to get the N classes we use for training\n",
    "    '''\n",
    "    labels = os.listdir(path)\n",
    "    labels = removeDS(labels)\n",
    "    \n",
    "    clip_nums = {}\n",
    "    for label in labels:\n",
    "        label_path = path + label + '/'\n",
    "        clips = os.listdir(label_path)\n",
    "        clips = removeDS(clips)\n",
    "        clip_nums[label] = len(clips)\n",
    "        \n",
    "    sortedClasses = sorted(clip_nums.items(), key = lambda item:item[1], reverse = True)\n",
    "    NClasses = sortedClasses[:N]\n",
    "    \n",
    "    NClasses_names = [c[0] for c in NClasses]\n",
    "    \n",
    "    return NClasses_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pick up from bin with tong or scooper', 'Put item into meal using tongs', 'Put tongs or scooper back in bin', 'Operating POS', 'Put item into meal using hands']\n"
     ]
    }
   ],
   "source": [
    "path = '../datasets/ucf24/labels/'\n",
    "N = 5\n",
    "NClasses_names = get_Nclasses(path, N)\n",
    "print(NClasses_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lists(path, list_root, NClasses_names, N):\n",
    "    '''\n",
    "    This function is used to build training and testing data list we're gonna use.\n",
    "    The label path (class/class_group_clip/frameidx.txt) will be stored in trainlist.txt\n",
    "    The clip path (class/class_group_clip) will be stored in trainlist01.txt\n",
    "    '''\n",
    "    labels = os.listdir(path)\n",
    "    labels = removeDS(labels)\n",
    "\n",
    "    train_refs_full = []\n",
    "    test_refs_full = []\n",
    "    \n",
    "    train_frames_full = []\n",
    "    test_frames_full = []\n",
    "\n",
    "    for label in labels:\n",
    "        label_path = path + label + '/'\n",
    "        clips = os.listdir(label_path)\n",
    "        clips = removeDS(clips)\n",
    "        num_clips = len(clips)\n",
    "        \n",
    "        if label in NClasses_names:\n",
    "            \n",
    "            train_num = int(num_clips*train_ratio) # round down, or there might be no data in testing at all\n",
    "\n",
    "            if clips: # if not empty\n",
    "                train_refs = clips[0:train_num]\n",
    "                test_refs = clips[train_num::]\n",
    "                \n",
    "                train_paths = [label + '/' + s for s in train_refs]\n",
    "                test_paths = [label + '/' + s for s in test_refs]\n",
    "                \n",
    "                for i in range(len(train_refs)):\n",
    "                    clip_ref = train_refs[i] # class_g_c\n",
    "                    clip_path = label_path + clip_ref + '/'\n",
    "                    frames = os.listdir(clip_path)\n",
    "                    frames = removeDS(frames)\n",
    "                    \n",
    "                    for frame in frames:\n",
    "                        frame_path = train_paths[i] + '/' + frame\n",
    "                        train_frames_full.append(frame_path)\n",
    "                        \n",
    "                for i in range(len(test_refs)):\n",
    "                    clip_ref = test_refs[i] # class_g_c\n",
    "                    clip_path = label_path + clip_ref + '/'\n",
    "                    frames = os.listdir(clip_path)\n",
    "                    frames = removeDS(frames)\n",
    "                    \n",
    "                    for frame in frames:\n",
    "                        frame_path = test_paths[i] + '/' + frame\n",
    "                        test_frames_full.append(frame_path)\n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "                '''\n",
    "                train_frames_full = []\n",
    "                test_frames_full = []\n",
    "                train_refs_full = []\n",
    "                test_refs_full = []\n",
    "                '''\n",
    "            train_refs_full += train_paths\n",
    "            test_refs_full += test_paths\n",
    "            \n",
    "            print(label + ':')\n",
    "            print('total clips: ' + str(len(clips)))\n",
    "            print('training clips: ' + str(len(train_refs)))\n",
    "            print('testing clips: ' + str(len(test_refs)))\n",
    "            print('===========================')\n",
    "\n",
    "    delimiter = '\\n'\n",
    "    \n",
    "    train_frame_str = delimiter.join(train_frames_full)\n",
    "    test_frame_str = delimiter.join(test_frames_full)\n",
    "    train_frame_path = list_root + 'trainlist_' + str(N) + '.txt'\n",
    "    test_frame_path = list_root + 'testlist_' + str(N) + '.txt'\n",
    "    \n",
    "    train_clip_str = delimiter.join(train_refs_full)\n",
    "    test_clip_str = delimiter.join(test_refs_full)\n",
    "    train_clip_path = list_root + 'trainlist01_' + str(N) + '.txt'\n",
    "    test_clip_path = list_root + 'testlist01_' + str(N) + '.txt'\n",
    "\n",
    "    file = open(train_frame_path,'w+') \n",
    "    file.write(train_frame_str)\n",
    "    file.close()\n",
    "    file = open(test_frame_path,'w+')\n",
    "    file.write(test_frame_str)\n",
    "    file.close()\n",
    "    \n",
    "    file = open(train_clip_path,'w+') \n",
    "    file.write(train_clip_str)\n",
    "    file.close()\n",
    "    file = open(test_clip_path,'w+')\n",
    "    file.write(test_clip_str)\n",
    "    file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating POS:\n",
      "total clips: 74\n",
      "training clips: 59\n",
      "testing clips: 15\n",
      "===========================\n",
      "Pick up from bin with tong or scooper:\n",
      "total clips: 149\n",
      "training clips: 119\n",
      "testing clips: 30\n",
      "===========================\n",
      "Put item into meal using hands:\n",
      "total clips: 66\n",
      "training clips: 52\n",
      "testing clips: 14\n",
      "===========================\n",
      "Put item into meal using tongs:\n",
      "total clips: 136\n",
      "training clips: 108\n",
      "testing clips: 28\n",
      "===========================\n",
      "Put tongs or scooper back in bin:\n",
      "total clips: 89\n",
      "training clips: 71\n",
      "testing clips: 18\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.8\n",
    "\n",
    "list_root = '../datasets/ucf24/splitfiles/' \n",
    "path = '../datasets/ucf24/labels/'    \n",
    "\n",
    "NClasses_names = get_Nclasses(path, N)\n",
    "build_lists(path, list_root, NClasses_names, N)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datasetName.names file\n",
    "These files for different dataset is stored in 'YOWO/data/', they contains all the classes names used for trainning for different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_class_names(NClasses_names, path, fileName):\n",
    "    delimiter = '\\n'\n",
    "    names_str = delimiter.join(NClasses_names)\n",
    "    names_path = path + fileName\n",
    "    file = open(names_path,'w+') \n",
    "    file.write(names_str)\n",
    "    file.close()\n",
    "\n",
    "'''\n",
    "path: folder path to save datasetNames.names files\n",
    "class_names: returned by build_labelref_list function, contains class names list\n",
    "'''\n",
    "\n",
    "path = '../YOWO/data/'\n",
    "fileName = 'restaurant_' + str(N) + '.names'\n",
    "build_class_names(NClasses_names, path, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
